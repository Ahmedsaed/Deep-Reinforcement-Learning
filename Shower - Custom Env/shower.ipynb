{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete \n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building The Environment\n",
    "- Random temperature \n",
    "- Ideal Temp. is 37-39  \n",
    "\n",
    "Goal: Build an agent to optimize the shower temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv(Env):\n",
    "    def __init__(self):\n",
    "        # Actions we can take, down, stay, up\n",
    "        self.action_space = Discrete(3)\n",
    "        # Temperature array\n",
    "        self.observation_space = Box(low=np.array([0]), high=np.array([100]))\n",
    "        # Set start temp\n",
    "        self.state = 38 + random.randint(-3,3)\n",
    "        # Set shower length\n",
    "        self.shower_length = 60\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Apply action\n",
    "        # 0 -1 = -1 temperature\n",
    "        # 1 -1 = 0 \n",
    "        # 2 -1 = 1 temperature \n",
    "        self.state += action -1 \n",
    "        # Reduce shower length by 1 second\n",
    "        self.shower_length -= 1 \n",
    "        \n",
    "        # Calculate reward\n",
    "        if self.state >=37 and self.state <=39: \n",
    "            reward =1 \n",
    "        else:\n",
    "            reward = -1 \n",
    "        \n",
    "        # Check if shower is done\n",
    "        if self.shower_length <= 0: \n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        \n",
    "        # Apply temperature noise\n",
    "        #self.state += random.randint(-1,1)\n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "        \n",
    "        # Return step information\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        # Reset shower temperature\n",
    "        self.state = np.array([38 + random.randint(-3,3)]).astype(float)\n",
    "        # Reset shower time\n",
    "        self.shower_length = 60 \n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python venv\\deep-RL-pytorch\\lib\\site-packages\\gym\\logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "env = ShowerEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-34\n",
      "Episode:2 Score:-18\n",
      "Episode:3 Score:22\n",
      "Episode:4 Score:-14\n",
      "Episode:5 Score:-18\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('Training', 'Logs')\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_path)\n",
    "save_path = os.path.join('Training', 'Saved Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_5\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60       |\n",
      "|    ep_rew_mean     | -31.2    |\n",
      "| time/              |          |\n",
      "|    fps             | 1162     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -29.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006294756 |\n",
      "|    clip_fraction        | 0.00762     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | -1.6e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49.6        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | 8.93e-05    |\n",
      "|    value_loss           | 84.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -25.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 673         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008806888 |\n",
      "|    clip_fraction        | 0.0597      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -5.15e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.1        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    value_loss           | 74.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -26.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 645          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080059515 |\n",
      "|    clip_fraction        | 0.052        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -7.53e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 36.5         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    value_loss           | 77.1         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-12.00 +/- 58.79\n",
      "Episode length: 60.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 60           |\n",
      "|    mean_reward          | -12          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075931977 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.000895    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 20.6         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | 0.000104     |\n",
      "|    value_loss           | 60.3         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | -27.2    |\n",
      "| time/              |          |\n",
      "|    fps             | 630      |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.4         |\n",
      "|    ep_rew_mean          | -26.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 625          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038916697 |\n",
      "|    clip_fraction        | 0.00586      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -5.95e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 34.1         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    value_loss           | 84.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.4         |\n",
      "|    ep_rew_mean          | -21          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 618          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029161237 |\n",
      "|    clip_fraction        | 0.0366       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.00173      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 34.2         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.000338    |\n",
      "|    value_loss           | 67.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -16.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 609          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023432826 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -4.14e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 37.7         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00132     |\n",
      "|    value_loss           | 73.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -16.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 605          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039182757 |\n",
      "|    clip_fraction        | 0.0708       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | -0.00517     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 34.7         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    value_loss           | 66.4         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=12.00 +/- 58.79\n",
      "Episode length: 60.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 60           |\n",
      "|    mean_reward          | 12           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 20000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043360135 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | -0.0033      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00831     |\n",
      "|    value_loss           | 59.3         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | -17.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 589      |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | -20.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 582        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 38         |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01066332 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | -0.00413   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 39         |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0119    |\n",
      "|    value_loss           | 66.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | -19.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 586         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006216551 |\n",
      "|    clip_fraction        | 0.0802      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -0.000438   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.5        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00532    |\n",
      "|    value_loss           | 68.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -13.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 586         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008741815 |\n",
      "|    clip_fraction        | 0.095       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.00313    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.4        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    value_loss           | 66          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -11         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005516791 |\n",
      "|    clip_fraction        | 0.0666      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -2.78e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00228    |\n",
      "|    value_loss           | 59.6        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=12.00 +/- 58.79\n",
      "Episode length: 60.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 60        |\n",
      "|    mean_reward          | 12        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 30000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0095714 |\n",
      "|    clip_fraction        | 0.133     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.05     |\n",
      "|    explained_variance   | 0.00238   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 35.5      |\n",
      "|    n_updates            | 200       |\n",
      "|    policy_gradient_loss | -0.00955  |\n",
      "|    value_loss           | 70.7      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | -5.86    |\n",
      "| time/              |          |\n",
      "|    fps             | 580      |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 52       |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | -5.54       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 573         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008416519 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.0093      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 58.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.4         |\n",
      "|    ep_rew_mean          | -0.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 572          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047800457 |\n",
      "|    clip_fraction        | 0.0798       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | -0.0115      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 30.6         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    value_loss           | 52.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 1.42         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 572          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 64           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065461975 |\n",
      "|    clip_fraction        | 0.0797       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.00234      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 29.3         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00146     |\n",
      "|    value_loss           | 49           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 4.7         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 572         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009471513 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.00163     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=36.00 +/- 48.00\n",
      "Episode length: 60.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 60           |\n",
      "|    mean_reward          | 36           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 40000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033109966 |\n",
      "|    clip_fraction        | 0.0877       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | -0.00764     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 28           |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.000897    |\n",
      "|    value_loss           | 47           |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 5.72     |\n",
      "| time/              |          |\n",
      "|    fps             | 570      |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 71       |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.4         |\n",
      "|    ep_rew_mean          | 10.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 570          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0148275355 |\n",
      "|    clip_fraction        | 0.223        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | -0.00724     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0219      |\n",
      "|    value_loss           | 42.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 12.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 572         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007508035 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.99       |\n",
      "|    explained_variance   | 0.00572     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    value_loss           | 36.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 16          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 573         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004406857 |\n",
      "|    clip_fraction        | 0.0823      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.981      |\n",
      "|    explained_variance   | 0.0022      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    value_loss           | 44.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 19.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 573         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011435451 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.976      |\n",
      "|    explained_variance   | -0.011      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 47.3        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-12.00 +/- 58.79\n",
      "Episode length: 60.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 60           |\n",
      "|    mean_reward          | -12          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 50000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045307595 |\n",
      "|    clip_fraction        | 0.179        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.957       |\n",
      "|    explained_variance   | -0.000321    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 24.2         |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | 0.00414      |\n",
      "|    value_loss           | 40           |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 25.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 570      |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 89       |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 30.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010464491 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.963      |\n",
      "|    explained_variance   | -0.000217   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    value_loss           | 49          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.4         |\n",
      "|    ep_rew_mean          | 34.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 569          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093092285 |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.949       |\n",
      "|    explained_variance   | -0.000226    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.000292    |\n",
      "|    value_loss           | 42.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 38.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006960879 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.939      |\n",
      "|    explained_variance   | -0.000119   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | 0.00194     |\n",
      "|    value_loss           | 51.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 43.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007766726 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.932      |\n",
      "|    explained_variance   | 2.81e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | 0.00747     |\n",
      "|    value_loss           | 60.7        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=60.00 +/- 0.00\n",
      "Episode length: 60.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 60           |\n",
      "|    mean_reward          | 60           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 60000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043414226 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.93        |\n",
      "|    explained_variance   | -1.86e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 29.2         |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | 0.00482      |\n",
      "|    value_loss           | 71.3         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 45.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 567      |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 108      |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 41.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 565         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023651566 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.932      |\n",
      "|    explained_variance   | 2.52e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | 0.000387    |\n",
      "|    value_loss           | 76.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 41.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 565         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008234028 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.936      |\n",
      "|    explained_variance   | -3.56e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.9        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    value_loss           | 76.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 42.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 565         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029022023 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.925      |\n",
      "|    explained_variance   | -1.6e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | 0.00937     |\n",
      "|    value_loss           | 67.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | 45.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 564        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02292868 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.921     |\n",
      "|    explained_variance   | -1.87e-05  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 47.7       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | 0.00463    |\n",
      "|    value_loss           | 74.2       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=60.00 +/- 0.00\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 60          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008493387 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.914      |\n",
      "|    explained_variance   | -1.6e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.4        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | 0.00245     |\n",
      "|    value_loss           | 83.6        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 48.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 564      |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 126      |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 60.4      |\n",
      "|    ep_rew_mean          | 48.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 564       |\n",
      "|    iterations           | 36        |\n",
      "|    time_elapsed         | 130       |\n",
      "|    total_timesteps      | 73728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0089862 |\n",
      "|    clip_fraction        | 0.182     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.907    |\n",
      "|    explained_variance   | 1.07e-06  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 45.2      |\n",
      "|    n_updates            | 410       |\n",
      "|    policy_gradient_loss | 0.00947   |\n",
      "|    value_loss           | 86.6      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 49.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 563         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010743417 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.897      |\n",
      "|    explained_variance   | -2.98e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.4        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | 0.00593     |\n",
      "|    value_loss           | 87.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | 49.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 562        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 138        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00938463 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.903     |\n",
      "|    explained_variance   | -1.79e-06  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 34.1       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | 0.0109     |\n",
      "|    value_loss           | 85.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 50.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012206761 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.92       |\n",
      "|    explained_variance   | -2.74e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.3        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | 0.0089      |\n",
      "|    value_loss           | 90.8        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=58.40 +/- 0.80\n",
      "Episode length: 60.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 60         |\n",
      "|    mean_reward          | 58.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 80000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01793951 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.926     |\n",
      "|    explained_variance   | 5.42e-06   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 51.7       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | 0.0108     |\n",
      "|    value_loss           | 95.7       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 50.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 561      |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 145      |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 47.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 561         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022645842 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.917      |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40          |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | 0.0142      |\n",
      "|    value_loss           | 91.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 43.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011792025 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.916      |\n",
      "|    explained_variance   | -5.25e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.7        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | 0.00649     |\n",
      "|    value_loss           | 88.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 43.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017648458 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.905      |\n",
      "|    explained_variance   | -1.01e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.9        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | 0.00753     |\n",
      "|    value_loss           | 81.8        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=60.00 +/- 0.00\n",
      "Episode length: 60.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 60         |\n",
      "|    mean_reward          | 60         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 90000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01220214 |\n",
      "|    clip_fraction        | 0.189      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.899     |\n",
      "|    explained_variance   | -2.71e-05  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 31.3       |\n",
      "|    n_updates            | 490        |\n",
      "|    policy_gradient_loss | 0.00649    |\n",
      "|    value_loss           | 82.2       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 47.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 559      |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 160      |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 50.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054427795 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.904      |\n",
      "|    explained_variance   | -3.34e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | 0.019       |\n",
      "|    value_loss           | 84.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 49.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013890389 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.909      |\n",
      "|    explained_variance   | -2.26e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43          |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | 0.00613     |\n",
      "|    value_loss           | 92.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 46.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036792055 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.904      |\n",
      "|    explained_variance   | 2.38e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 69.8        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | 0.0127      |\n",
      "|    value_loss           | 87.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 45.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013072876 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.902      |\n",
      "|    explained_variance   | 1.09e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.7        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | 0.00449     |\n",
      "|    value_loss           | 88.2        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=59.20 +/- 0.98\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 59.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009187092 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.899      |\n",
      "|    explained_variance   | 4.95e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.2        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | 0.00568     |\n",
      "|    value_loss           | 83.7        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 46.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 560      |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 179      |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 43.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025571529 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.894      |\n",
      "|    explained_variance   | 8.46e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | 0.00616     |\n",
      "|    value_loss           | 82.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 37.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016060315 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.883      |\n",
      "|    explained_variance   | 2.72e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.2        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | 0.0104      |\n",
      "|    value_loss           | 76.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 39.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016126286 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.881      |\n",
      "|    explained_variance   | 0.00103     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.2        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    value_loss           | 65.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 44.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023626287 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.87       |\n",
      "|    explained_variance   | 0.00224     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41          |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | 0.00256     |\n",
      "|    value_loss           | 69.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=60.00 +/- 0.00\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 60          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 110000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038559236 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.858      |\n",
      "|    explained_variance   | 0.000783    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.6        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | 0.0175      |\n",
      "|    value_loss           | 79          |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 49.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 558      |\n",
      "|    iterations      | 54       |\n",
      "|    time_elapsed    | 198      |\n",
      "|    total_timesteps | 110592   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 51.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 558         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 201         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013337157 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.838      |\n",
      "|    explained_variance   | 0.000141    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | 0.0182      |\n",
      "|    value_loss           | 80.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 52          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015496634 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.842      |\n",
      "|    explained_variance   | 5.58e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.7        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | 0.0181      |\n",
      "|    value_loss           | 89.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 54.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 558         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020749185 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.845      |\n",
      "|    explained_variance   | -8.46e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 54.8        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | 0.00932     |\n",
      "|    value_loss           | 94.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | 55.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 559        |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 212        |\n",
      "|    total_timesteps      | 118784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01810006 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.833     |\n",
      "|    explained_variance   | -1.62e-05  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 61         |\n",
      "|    n_updates            | 630        |\n",
      "|    policy_gradient_loss | 0.00976    |\n",
      "|    value_loss           | 101        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=59.20 +/- 0.98\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 59.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 120000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019549513 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.853      |\n",
      "|    explained_variance   | -1.07e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.8        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | 0.0128      |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 55.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 556      |\n",
      "|    iterations      | 59       |\n",
      "|    time_elapsed    | 217      |\n",
      "|    total_timesteps | 120832   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | 55.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 556        |\n",
      "|    iterations           | 60         |\n",
      "|    time_elapsed         | 220        |\n",
      "|    total_timesteps      | 122880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03281697 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.847     |\n",
      "|    explained_variance   | -2.26e-06  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 46.1       |\n",
      "|    n_updates            | 650        |\n",
      "|    policy_gradient_loss | 0.0165     |\n",
      "|    value_loss           | 108        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.4         |\n",
      "|    ep_rew_mean          | 52.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 555          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 224          |\n",
      "|    total_timesteps      | 124928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0151920775 |\n",
      "|    clip_fraction        | 0.235        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.844       |\n",
      "|    explained_variance   | -6.68e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 56.6         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | 0.0173       |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 51.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 554         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045298997 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.854      |\n",
      "|    explained_variance   | -2.28e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75          |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | 0.0109      |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 51.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 554          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 232          |\n",
      "|    total_timesteps      | 129024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072424235 |\n",
      "|    clip_fraction        | 0.205        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.861       |\n",
      "|    explained_variance   | -9.3e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 64.9         |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | 0.0145       |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=59.20 +/- 0.98\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 59.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 130000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012138972 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.852      |\n",
      "|    explained_variance   | 3.52e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.4        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | 0.0153      |\n",
      "|    value_loss           | 99          |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 52.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 555      |\n",
      "|    iterations      | 64       |\n",
      "|    time_elapsed    | 235      |\n",
      "|    total_timesteps | 131072   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 51.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 556         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030456418 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.837      |\n",
      "|    explained_variance   | 1.02e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.8        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | 0.0149      |\n",
      "|    value_loss           | 95.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 53.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 556         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 243         |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018677993 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.819      |\n",
      "|    explained_variance   | 1.42e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48.7        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | 0.00724     |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 54.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 556         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 246         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009708213 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.809      |\n",
      "|    explained_variance   | 1.59e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.3        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | 0.0142      |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 53.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 556         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005198194 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.803      |\n",
      "|    explained_variance   | 6.68e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.3        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | 0.00899     |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=59.60 +/- 0.80\n",
      "Episode length: 60.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 60         |\n",
      "|    mean_reward          | 59.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 140000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02820057 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.795     |\n",
      "|    explained_variance   | 1.19e-06   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 59.4       |\n",
      "|    n_updates            | 740        |\n",
      "|    policy_gradient_loss | 0.0178     |\n",
      "|    value_loss           | 102        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 54.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 555      |\n",
      "|    iterations      | 69       |\n",
      "|    time_elapsed    | 254      |\n",
      "|    total_timesteps | 141312   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.4         |\n",
      "|    ep_rew_mean          | 54.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 555          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 258          |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077905552 |\n",
      "|    clip_fraction        | 0.19         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.795       |\n",
      "|    explained_variance   | -4.17e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 52.4         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | 0.0116       |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 52.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 555         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020731911 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.804      |\n",
      "|    explained_variance   | -3.7e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52          |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | 0.00988     |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 51.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 550          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 268          |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072726216 |\n",
      "|    clip_fraction        | 0.157        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.8         |\n",
      "|    explained_variance   | -1.16e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 51.5         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | 0.00429      |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | 51.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 546        |\n",
      "|    iterations           | 73         |\n",
      "|    time_elapsed         | 273        |\n",
      "|    total_timesteps      | 149504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01703453 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.795     |\n",
      "|    explained_variance   | 7.87e-06   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 62.8       |\n",
      "|    n_updates            | 780        |\n",
      "|    policy_gradient_loss | 0.0103     |\n",
      "|    value_loss           | 97.1       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=59.60 +/- 0.80\n",
      "Episode length: 60.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 60           |\n",
      "|    mean_reward          | 59.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 150000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046272622 |\n",
      "|    clip_fraction        | 0.189        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.798       |\n",
      "|    explained_variance   | 1.2e-05      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 52.1         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | 0.0105       |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 53.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 541      |\n",
      "|    iterations      | 74       |\n",
      "|    time_elapsed    | 279      |\n",
      "|    total_timesteps | 151552   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | 53.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 539        |\n",
      "|    iterations           | 75         |\n",
      "|    time_elapsed         | 284        |\n",
      "|    total_timesteps      | 153600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03548388 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.799     |\n",
      "|    explained_variance   | 3.58e-06   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 38.2       |\n",
      "|    n_updates            | 800        |\n",
      "|    policy_gradient_loss | 0.0123     |\n",
      "|    value_loss           | 100        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 45.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 535         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 290         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037001014 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.798      |\n",
      "|    explained_variance   | 3.52e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 69.2        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | 0.0181      |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 36.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 531         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 296         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015335693 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.807      |\n",
      "|    explained_variance   | 2.78e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.7        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    value_loss           | 94.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 37.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 527         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 302         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027028427 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.815      |\n",
      "|    explained_variance   | 8.18e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.5        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | 0.000452    |\n",
      "|    value_loss           | 65.8        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=59.20 +/- 0.98\n",
      "Episode length: 60.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 60         |\n",
      "|    mean_reward          | 59.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 160000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01024431 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.82      |\n",
      "|    explained_variance   | 9.78e-05   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 38.4       |\n",
      "|    n_updates            | 840        |\n",
      "|    policy_gradient_loss | 0.0173     |\n",
      "|    value_loss           | 70.4       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 46.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 527      |\n",
      "|    iterations      | 79       |\n",
      "|    time_elapsed    | 306      |\n",
      "|    total_timesteps | 161792   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | 51.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 528        |\n",
      "|    iterations           | 80         |\n",
      "|    time_elapsed         | 310        |\n",
      "|    total_timesteps      | 163840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02907009 |\n",
      "|    clip_fraction        | 0.212      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.827     |\n",
      "|    explained_variance   | -2.66e-05  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 45.3       |\n",
      "|    n_updates            | 850        |\n",
      "|    policy_gradient_loss | 0.0133     |\n",
      "|    value_loss           | 80.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 50.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 313         |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016348122 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.825      |\n",
      "|    explained_variance   | -0.000158   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.4        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | 0.0075      |\n",
      "|    value_loss           | 89.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 48.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008275953 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.808      |\n",
      "|    explained_variance   | 4.23e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.1        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | 0.00771     |\n",
      "|    value_loss           | 87          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 47.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 323         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035451837 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.789      |\n",
      "|    explained_variance   | -6.2e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.8        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | 0.0127      |\n",
      "|    value_loss           | 92.4        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=36.00 +/- 48.00\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 36          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 170000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008347418 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.758      |\n",
      "|    explained_variance   | -4.35e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48.8        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | 0.00713     |\n",
      "|    value_loss           | 87.6        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 43       |\n",
      "| time/              |          |\n",
      "|    fps             | 522      |\n",
      "|    iterations      | 84       |\n",
      "|    time_elapsed    | 329      |\n",
      "|    total_timesteps | 172032   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 44.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 334         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015376285 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.748      |\n",
      "|    explained_variance   | 0.000119    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.1        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | 0.00174     |\n",
      "|    value_loss           | 74.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 48.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 518         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008206417 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.742      |\n",
      "|    explained_variance   | 4.05e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48.7        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | 0.00996     |\n",
      "|    value_loss           | 81.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 52.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 347         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020763164 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.736      |\n",
      "|    explained_variance   | 0.000108    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.3        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | 0.00949     |\n",
      "|    value_loss           | 93.8        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=12.00 +/- 58.79\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 12          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 180000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011868946 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.72       |\n",
      "|    explained_variance   | 3.87e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.3        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | 0.0101      |\n",
      "|    value_loss           | 97.8        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 49.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 509      |\n",
      "|    iterations      | 88       |\n",
      "|    time_elapsed    | 353      |\n",
      "|    total_timesteps | 180224   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 49.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 360         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021152021 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.673      |\n",
      "|    explained_variance   | 5.86e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.9        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | 0.0058      |\n",
      "|    value_loss           | 91          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 50.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 366         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008459538 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.667      |\n",
      "|    explained_variance   | 3.99e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 58          |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | 0.00782     |\n",
      "|    value_loss           | 91.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 54.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 498          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 373          |\n",
      "|    total_timesteps      | 186368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075482344 |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.637       |\n",
      "|    explained_variance   | 1.88e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 42.8         |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | 0.012        |\n",
      "|    value_loss           | 98.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 55.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 379         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011241553 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.602      |\n",
      "|    explained_variance   | 7.75e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.7        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | 0.0122      |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=58.80 +/- 0.98\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 58.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 190000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023306286 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.648      |\n",
      "|    explained_variance   | -1.08e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.4        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | 0.0108      |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 57.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 492      |\n",
      "|    iterations      | 93       |\n",
      "|    time_elapsed    | 386      |\n",
      "|    total_timesteps | 190464   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 57.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 490         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 392         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005626633 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.667      |\n",
      "|    explained_variance   | 4.17e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59          |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | 0.0172      |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | 57.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 488        |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 398        |\n",
      "|    total_timesteps      | 194560     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05812691 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.655     |\n",
      "|    explained_variance   | 1.13e-06   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 56.9       |\n",
      "|    n_updates            | 1000       |\n",
      "|    policy_gradient_loss | 0.0191     |\n",
      "|    value_loss           | 116        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 58.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 486         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024972834 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.595      |\n",
      "|    explained_variance   | 8.94e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59.5        |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | 0.0126      |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 57.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 485         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 409         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005702079 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.602      |\n",
      "|    explained_variance   | 2.32e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 74.9        |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | 0.0187      |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=59.60 +/- 0.80\n",
      "Episode length: 60.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 60           |\n",
      "|    mean_reward          | 59.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 200000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057986258 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.613       |\n",
      "|    explained_variance   | 4.23e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 57.4         |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | 0.0105       |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 57.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 483      |\n",
      "|    iterations      | 98       |\n",
      "|    time_elapsed    | 415      |\n",
      "|    total_timesteps | 200704   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 57.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 482         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 420         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027547693 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.605      |\n",
      "|    explained_variance   | 2.8e-06     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 71          |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | 0.0115      |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 57.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 480         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 426         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007358909 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.631      |\n",
      "|    explained_variance   | 1.19e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59.1        |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | 0.0104      |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 57.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 477          |\n",
      "|    iterations           | 101          |\n",
      "|    time_elapsed         | 433          |\n",
      "|    total_timesteps      | 206848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061227307 |\n",
      "|    clip_fraction        | 0.167        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.616       |\n",
      "|    explained_variance   | 3.46e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 47.9         |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | 0.012        |\n",
      "|    value_loss           | 122          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 57.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 474         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 440         |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012048104 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.613      |\n",
      "|    explained_variance   | -1.29e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.3        |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | 0.0117      |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=59.20 +/- 0.98\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 59.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 210000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024818657 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.612      |\n",
      "|    explained_variance   | -3.22e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 54.9        |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | 0.0133      |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 58.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 470      |\n",
      "|    iterations      | 103      |\n",
      "|    time_elapsed    | 448      |\n",
      "|    total_timesteps | 210944   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 58.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 467         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 455         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011732962 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.605      |\n",
      "|    explained_variance   | 4.71e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48.7        |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | 0.0109      |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.4         |\n",
      "|    ep_rew_mean          | 57.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 105          |\n",
      "|    time_elapsed         | 462          |\n",
      "|    total_timesteps      | 215040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065533724 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.589       |\n",
      "|    explained_variance   | -1.07e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 77.5         |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | 0.00705      |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 55.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 462          |\n",
      "|    iterations           | 106          |\n",
      "|    time_elapsed         | 469          |\n",
      "|    total_timesteps      | 217088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0156203965 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.605       |\n",
      "|    explained_variance   | 3.34e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 67.9         |\n",
      "|    n_updates            | 1110         |\n",
      "|    policy_gradient_loss | 0.00981      |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 52.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 477         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007837116 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.62       |\n",
      "|    explained_variance   | 5.48e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 71.2        |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | 0.00831     |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=12.00 +/- 58.79\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 12          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 220000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006307435 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.598      |\n",
      "|    explained_variance   | 4.85e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61          |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | 0.00267     |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 51.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 108      |\n",
      "|    time_elapsed    | 482      |\n",
      "|    total_timesteps | 221184   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 52.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 456         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 488         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009973405 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.587      |\n",
      "|    explained_variance   | 6.51e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.4        |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | 0.0119      |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 54.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 455         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 494         |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018993635 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.591      |\n",
      "|    explained_variance   | 5.76e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.1        |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | 0.0106      |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 60        |\n",
      "|    ep_rew_mean          | 54        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 454       |\n",
      "|    iterations           | 111       |\n",
      "|    time_elapsed         | 500       |\n",
      "|    total_timesteps      | 227328    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0107377 |\n",
      "|    clip_fraction        | 0.122     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.592    |\n",
      "|    explained_variance   | 9.85e-05  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 52.2      |\n",
      "|    n_updates            | 1160      |\n",
      "|    policy_gradient_loss | 0.0113    |\n",
      "|    value_loss           | 110       |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 54.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 453          |\n",
      "|    iterations           | 112          |\n",
      "|    time_elapsed         | 505          |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062105376 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.583       |\n",
      "|    explained_variance   | 0.000225     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 47.8         |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | 0.0112       |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=60.00 +/- 0.00\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 60          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 230000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016708085 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.565      |\n",
      "|    explained_variance   | -3.99e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 54.9        |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | 0.00967     |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 56.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 451      |\n",
      "|    iterations      | 113      |\n",
      "|    time_elapsed    | 512      |\n",
      "|    total_timesteps | 231424   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 58.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 449         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 519         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016859744 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.529      |\n",
      "|    explained_variance   | -1.41e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 71.4        |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | 0.0181      |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 57.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 446         |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 526         |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017511815 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.507      |\n",
      "|    explained_variance   | -9.54e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38          |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | 0.0101      |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 56.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 444         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 534         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019005349 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | -0.000105   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64.4        |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | 0.0142      |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 56.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 443         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 540         |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008231408 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.481      |\n",
      "|    explained_variance   | -7.15e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.2        |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | 0.00779     |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=35.20 +/- 47.61\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 35.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 240000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010741634 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.477      |\n",
      "|    explained_variance   | -4.82e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.5        |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | 0.0111      |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 57       |\n",
      "| time/              |          |\n",
      "|    fps             | 441      |\n",
      "|    iterations      | 118      |\n",
      "|    time_elapsed    | 547      |\n",
      "|    total_timesteps | 241664   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.4         |\n",
      "|    ep_rew_mean          | 57.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 439          |\n",
      "|    iterations           | 119          |\n",
      "|    time_elapsed         | 554          |\n",
      "|    total_timesteps      | 243712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053726276 |\n",
      "|    clip_fraction        | 0.0967       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | -2.48e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 80.4         |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | 0.00824      |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 55.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 437         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 561         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010001831 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.518      |\n",
      "|    explained_variance   | 1.73e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.2        |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | 0.00942     |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 55.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 437         |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 566         |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009924336 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.533      |\n",
      "|    explained_variance   | -3.81e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59.4        |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | 0.00928     |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 54.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 436         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 571         |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015824888 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.533      |\n",
      "|    explained_variance   | -4.52e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.6        |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | 0.0135      |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=60.00 +/- 0.00\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 60          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 250000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009607552 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.52       |\n",
      "|    explained_variance   | 8.11e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42          |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | 0.00826     |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 57.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 436      |\n",
      "|    iterations      | 123      |\n",
      "|    time_elapsed    | 577      |\n",
      "|    total_timesteps | 251904   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.4         |\n",
      "|    ep_rew_mean          | 57.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 435          |\n",
      "|    iterations           | 124          |\n",
      "|    time_elapsed         | 582          |\n",
      "|    total_timesteps      | 253952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069381935 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.527       |\n",
      "|    explained_variance   | 6.14e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 44.2         |\n",
      "|    n_updates            | 1290         |\n",
      "|    policy_gradient_loss | 0.0131       |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 58          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 435         |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 588         |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017703801 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.53       |\n",
      "|    explained_variance   | -8.58e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.3        |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | 0.0135      |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 57.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 434         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 593         |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025056433 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.526      |\n",
      "|    explained_variance   | -7.51e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.5        |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | 0.0121      |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=12.00 +/- 58.79\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 12          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 260000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003938351 |\n",
      "|    clip_fraction        | 0.087       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.488      |\n",
      "|    explained_variance   | -3.93e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 87.3        |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | 0.00631     |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 57       |\n",
      "| time/              |          |\n",
      "|    fps             | 434      |\n",
      "|    iterations      | 127      |\n",
      "|    time_elapsed    | 599      |\n",
      "|    total_timesteps | 260096   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 56.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 433         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 605         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023261596 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.503      |\n",
      "|    explained_variance   | -2.06e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49.4        |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | 0.00753     |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 56.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 431         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 612         |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013439863 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.485      |\n",
      "|    explained_variance   | -6.79e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.5        |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | 0.00697     |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 56.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 429         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 619         |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029522784 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.501      |\n",
      "|    explained_variance   | -4.77e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.1        |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | 0.00843     |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 56.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 428          |\n",
      "|    iterations           | 131          |\n",
      "|    time_elapsed         | 626          |\n",
      "|    total_timesteps      | 268288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071595414 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 2.38e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 67.3         |\n",
      "|    n_updates            | 1360         |\n",
      "|    policy_gradient_loss | 0.0103       |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=60.00 +/- 0.00\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 60          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 270000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007810306 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.535      |\n",
      "|    explained_variance   | -2.86e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 67.7        |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | 0.00866     |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 56.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 426      |\n",
      "|    iterations      | 132      |\n",
      "|    time_elapsed    | 634      |\n",
      "|    total_timesteps | 270336   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 56.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 425         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 640         |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011197992 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.533      |\n",
      "|    explained_variance   | -1.67e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.5        |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | 0.011       |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 55.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 423         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 647         |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008046924 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.562      |\n",
      "|    explained_variance   | 3.1e-06     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 68.1        |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | 0.00994     |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | 55.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 422        |\n",
      "|    iterations           | 135        |\n",
      "|    time_elapsed         | 654        |\n",
      "|    total_timesteps      | 276480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05487496 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.55      |\n",
      "|    explained_variance   | 9.42e-06   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 54.7       |\n",
      "|    n_updates            | 1400       |\n",
      "|    policy_gradient_loss | 0.0109     |\n",
      "|    value_loss           | 115        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 55.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 421         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 661         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013527374 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.534      |\n",
      "|    explained_variance   | -1.94e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.5        |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | 0.00905     |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=59.20 +/- 0.98\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 59.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 280000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010978179 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.523      |\n",
      "|    explained_variance   | 4.05e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48.1        |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | 0.0104      |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 57.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 420      |\n",
      "|    iterations      | 137      |\n",
      "|    time_elapsed    | 667      |\n",
      "|    total_timesteps | 280576   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 57.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 420         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 672         |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024670485 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.518      |\n",
      "|    explained_variance   | -2.62e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48.7        |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | 0.0114      |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 58.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 420         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 677         |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006043714 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.533      |\n",
      "|    explained_variance   | 9.54e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.2        |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | 0.0119      |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 57.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 419         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 683         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037165947 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.54       |\n",
      "|    explained_variance   | 3.16e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.8        |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | 0.0169      |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 57.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 419          |\n",
      "|    iterations           | 141          |\n",
      "|    time_elapsed         | 688          |\n",
      "|    total_timesteps      | 288768       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035768417 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.52        |\n",
      "|    explained_variance   | -3.93e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 45.8         |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | 0.0131       |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=59.20 +/- 0.98\n",
      "Episode length: 60.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 60           |\n",
      "|    mean_reward          | 59.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 290000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110661825 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | -7.87e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 59           |\n",
      "|    n_updates            | 1470         |\n",
      "|    policy_gradient_loss | 0.0129       |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 57.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 417      |\n",
      "|    iterations      | 142      |\n",
      "|    time_elapsed    | 696      |\n",
      "|    total_timesteps | 290816   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 57.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 702         |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023201551 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.522      |\n",
      "|    explained_variance   | -4.65e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.1        |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | 0.0123      |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 57.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 415         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 709         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012532154 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.516      |\n",
      "|    explained_variance   | -1.31e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 58.4        |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | 0.0106      |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 56.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 414         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 716         |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015669083 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.516      |\n",
      "|    explained_variance   | 3.58e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.9        |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | 0.0106      |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 56.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 413         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 723         |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015018243 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.546      |\n",
      "|    explained_variance   | 1.61e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.4        |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | 0.0104      |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=59.60 +/- 0.80\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 59.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 300000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005713152 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.552      |\n",
      "|    explained_variance   | 4.47e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43.7        |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | 0.00864     |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 56.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 411      |\n",
      "|    iterations      | 147      |\n",
      "|    time_elapsed    | 730      |\n",
      "|    total_timesteps | 301056   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.4         |\n",
      "|    ep_rew_mean          | 57.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 410          |\n",
      "|    iterations           | 148          |\n",
      "|    time_elapsed         | 738          |\n",
      "|    total_timesteps      | 303104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064139585 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.541       |\n",
      "|    explained_variance   | -5.01e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 49.8         |\n",
      "|    n_updates            | 1530         |\n",
      "|    policy_gradient_loss | 0.00819      |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 57.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 409         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 745         |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010062546 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.547      |\n",
      "|    explained_variance   | -1.07e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40          |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | 0.0121      |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 56.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 408          |\n",
      "|    iterations           | 150          |\n",
      "|    time_elapsed         | 751          |\n",
      "|    total_timesteps      | 307200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069382545 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.566       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 65.2         |\n",
      "|    n_updates            | 1550         |\n",
      "|    policy_gradient_loss | 0.0086       |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 56.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 408          |\n",
      "|    iterations           | 151          |\n",
      "|    time_elapsed         | 756          |\n",
      "|    total_timesteps      | 309248       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063593583 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.553       |\n",
      "|    explained_variance   | -1.91e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 70.3         |\n",
      "|    n_updates            | 1560         |\n",
      "|    policy_gradient_loss | 0.00846      |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=12.00 +/- 58.79\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 12          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 310000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018076854 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.56       |\n",
      "|    explained_variance   | -9.54e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 58.3        |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | 0.0193      |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 48.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 408      |\n",
      "|    iterations      | 152      |\n",
      "|    time_elapsed    | 762      |\n",
      "|    total_timesteps | 311296   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 45.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 408         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 767         |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023467984 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.521      |\n",
      "|    explained_variance   | 3.28e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 67.1        |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | 0.0016      |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 44.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 407         |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 773         |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007820527 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.503      |\n",
      "|    explained_variance   | 0.00122     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.3        |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | 0.00518     |\n",
      "|    value_loss           | 97.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 51           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 406          |\n",
      "|    iterations           | 155          |\n",
      "|    time_elapsed         | 780          |\n",
      "|    total_timesteps      | 317440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076134535 |\n",
      "|    clip_fraction        | 0.0863       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.000925     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 44.6         |\n",
      "|    n_updates            | 1600         |\n",
      "|    policy_gradient_loss | 0.0057       |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 49.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 405         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 787         |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036760762 |\n",
      "|    clip_fraction        | 0.0992      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.498      |\n",
      "|    explained_variance   | 0.000684    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 54.1        |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | 0.00682     |\n",
      "|    value_loss           | 95.6        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=60.00 +/- 0.00\n",
      "Episode length: 60.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 60         |\n",
      "|    mean_reward          | 60         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 320000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02589261 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.502     |\n",
      "|    explained_variance   | 0.000895   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 60.7       |\n",
      "|    n_updates            | 1620       |\n",
      "|    policy_gradient_loss | 0.00241    |\n",
      "|    value_loss           | 101        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 49.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 405      |\n",
      "|    iterations      | 157      |\n",
      "|    time_elapsed    | 793      |\n",
      "|    total_timesteps | 321536   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 50.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 800         |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048250683 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.487      |\n",
      "|    explained_variance   | 0.00205     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.6        |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | 0.0106      |\n",
      "|    value_loss           | 96.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 53.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 807         |\n",
      "|    total_timesteps      | 325632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008102717 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.46       |\n",
      "|    explained_variance   | 0.000453    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.8        |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | 0.011       |\n",
      "|    value_loss           | 96          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 51.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 402          |\n",
      "|    iterations           | 160          |\n",
      "|    time_elapsed         | 813          |\n",
      "|    total_timesteps      | 327680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057744263 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.454       |\n",
      "|    explained_variance   | 0.000318     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 58.3         |\n",
      "|    n_updates            | 1650         |\n",
      "|    policy_gradient_loss | 0.0102       |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | 52.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 401        |\n",
      "|    iterations           | 161        |\n",
      "|    time_elapsed         | 820        |\n",
      "|    total_timesteps      | 329728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01995036 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.463     |\n",
      "|    explained_variance   | 0.00115    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 48.6       |\n",
      "|    n_updates            | 1660       |\n",
      "|    policy_gradient_loss | 0.00681    |\n",
      "|    value_loss           | 110        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=35.20 +/- 47.61\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 35.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 330000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023479443 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.483      |\n",
      "|    explained_variance   | 0.000841    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43.9        |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | 0.0116      |\n",
      "|    value_loss           | 98.3        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 52.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 400      |\n",
      "|    iterations      | 162      |\n",
      "|    time_elapsed    | 827      |\n",
      "|    total_timesteps | 331776   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 56.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 400         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 833         |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014103435 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.492      |\n",
      "|    explained_variance   | 0.000403    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.2        |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | 0.0146      |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 57.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 400         |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 838         |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007837331 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.465      |\n",
      "|    explained_variance   | 0.000795    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.5        |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | 0.0117      |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 57.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 400          |\n",
      "|    iterations           | 165          |\n",
      "|    time_elapsed         | 843          |\n",
      "|    total_timesteps      | 337920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069118547 |\n",
      "|    clip_fraction        | 0.0985       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | -0.000389    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 54.6         |\n",
      "|    n_updates            | 1700         |\n",
      "|    policy_gradient_loss | 0.0112       |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 57.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 400         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 849         |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003534754 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.456      |\n",
      "|    explained_variance   | -4.17e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.2        |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | 0.02        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=59.20 +/- 0.98\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 59.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 340000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027274193 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.468      |\n",
      "|    explained_variance   | 1.29e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48.6        |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | 0.00922     |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 57.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 400      |\n",
      "|    iterations      | 167      |\n",
      "|    time_elapsed    | 854      |\n",
      "|    total_timesteps | 342016   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | 58.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 399        |\n",
      "|    iterations           | 168        |\n",
      "|    time_elapsed         | 861        |\n",
      "|    total_timesteps      | 344064     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04330291 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.471     |\n",
      "|    explained_variance   | -3.98e-05  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 71.7       |\n",
      "|    n_updates            | 1730       |\n",
      "|    policy_gradient_loss | 0.0148     |\n",
      "|    value_loss           | 117        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 57.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 398          |\n",
      "|    iterations           | 169          |\n",
      "|    time_elapsed         | 868          |\n",
      "|    total_timesteps      | 346112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037582521 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | -2.9e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 67.2         |\n",
      "|    n_updates            | 1740         |\n",
      "|    policy_gradient_loss | 0.012        |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 57.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 397          |\n",
      "|    iterations           | 170          |\n",
      "|    time_elapsed         | 875          |\n",
      "|    total_timesteps      | 348160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049471916 |\n",
      "|    clip_fraction        | 0.0984       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.47        |\n",
      "|    explained_variance   | -2.35e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 36.2         |\n",
      "|    n_updates            | 1750         |\n",
      "|    policy_gradient_loss | 0.00809      |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=35.60 +/- 47.81\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 35.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 350000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029916221 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.459      |\n",
      "|    explained_variance   | -3.3e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.4        |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | 0.0147      |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 57.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 396      |\n",
      "|    iterations      | 171      |\n",
      "|    time_elapsed    | 882      |\n",
      "|    total_timesteps | 350208   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 57          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 396         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 889         |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009001236 |\n",
      "|    clip_fraction        | 0.0799      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.452      |\n",
      "|    explained_variance   | -6.7e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.4        |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | 0.00578     |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 54.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 395         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 896         |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010788551 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.455      |\n",
      "|    explained_variance   | -8.11e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.7        |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | 0.0155      |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 52          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 394         |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 903         |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016341105 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.463      |\n",
      "|    explained_variance   | -5.46e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 58.4        |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | 0.00458     |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 51.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 393         |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 910         |\n",
      "|    total_timesteps      | 358400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010345546 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.49       |\n",
      "|    explained_variance   | -8.42e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.6        |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | 0.0102      |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=59.20 +/- 0.98\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 59.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 360000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006324552 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.481      |\n",
      "|    explained_variance   | -1.07e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53          |\n",
      "|    n_updates            | 1810        |\n",
      "|    policy_gradient_loss | 0.0095      |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 54.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 393      |\n",
      "|    iterations      | 176      |\n",
      "|    time_elapsed    | 915      |\n",
      "|    total_timesteps | 360448   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 56.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 393         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 921         |\n",
      "|    total_timesteps      | 362496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013460269 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.45       |\n",
      "|    explained_variance   | 2.07e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 79          |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | 0.00664     |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 57.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 393         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 926         |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005677092 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.44       |\n",
      "|    explained_variance   | 5.89e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.9        |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | 0.0109      |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 57.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 393          |\n",
      "|    iterations           | 179          |\n",
      "|    time_elapsed         | 932          |\n",
      "|    total_timesteps      | 366592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045369565 |\n",
      "|    clip_fraction        | 0.0702       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.434       |\n",
      "|    explained_variance   | 3.68e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 60.7         |\n",
      "|    n_updates            | 1840         |\n",
      "|    policy_gradient_loss | 0.0059       |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 58.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 392         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 938         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005838967 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.427      |\n",
      "|    explained_variance   | -2.26e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.2        |\n",
      "|    n_updates            | 1850        |\n",
      "|    policy_gradient_loss | 0.0161      |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=370000, episode_reward=60.00 +/- 0.00\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 60          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 370000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028654821 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.427      |\n",
      "|    explained_variance   | -5.72e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.3        |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | 0.00876     |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 58.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 392      |\n",
      "|    iterations      | 181      |\n",
      "|    time_elapsed    | 945      |\n",
      "|    total_timesteps | 370688   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 58.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 391         |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 951         |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016105168 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.442      |\n",
      "|    explained_variance   | -1.79e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.4        |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | 0.0109      |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | 57.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 391        |\n",
      "|    iterations           | 183        |\n",
      "|    time_elapsed         | 958        |\n",
      "|    total_timesteps      | 374784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00507378 |\n",
      "|    clip_fraction        | 0.0911     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.445     |\n",
      "|    explained_variance   | 8.34e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 59         |\n",
      "|    n_updates            | 1880       |\n",
      "|    policy_gradient_loss | 0.00793    |\n",
      "|    value_loss           | 124        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 56.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 390         |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 965         |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024261773 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.462      |\n",
      "|    explained_variance   | -4.77e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.1        |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | 0.00912     |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 52.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 389          |\n",
      "|    iterations           | 185          |\n",
      "|    time_elapsed         | 971          |\n",
      "|    total_timesteps      | 378880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055830637 |\n",
      "|    clip_fraction        | 0.0847       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 2.74e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 63.8         |\n",
      "|    n_updates            | 1900         |\n",
      "|    policy_gradient_loss | 0.00502      |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=35.20 +/- 47.61\n",
      "Episode length: 60.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 60         |\n",
      "|    mean_reward          | 35.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 380000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00655564 |\n",
      "|    clip_fraction        | 0.0825     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.452     |\n",
      "|    explained_variance   | 0.000104   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 40.4       |\n",
      "|    n_updates            | 1910       |\n",
      "|    policy_gradient_loss | 0.00306    |\n",
      "|    value_loss           | 112        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 41.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 389      |\n",
      "|    iterations      | 186      |\n",
      "|    time_elapsed    | 979      |\n",
      "|    total_timesteps | 380928   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 37.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 388         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 985         |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037464716 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.484      |\n",
      "|    explained_variance   | 0.000687    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48.2        |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 40          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 388         |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 992         |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017779551 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.476      |\n",
      "|    explained_variance   | 0.000217    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43.5        |\n",
      "|    n_updates            | 1930        |\n",
      "|    policy_gradient_loss | 0.0023      |\n",
      "|    value_loss           | 78.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 46.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 387         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 997         |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034841403 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.495      |\n",
      "|    explained_variance   | 0.000359    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.7        |\n",
      "|    n_updates            | 1940        |\n",
      "|    policy_gradient_loss | 0.00657     |\n",
      "|    value_loss           | 81.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 51.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 387         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 1003        |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015768431 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.509      |\n",
      "|    explained_variance   | 0.000569    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.4        |\n",
      "|    n_updates            | 1950        |\n",
      "|    policy_gradient_loss | 0.00786     |\n",
      "|    value_loss           | 82.7        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=59.60 +/- 0.80\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 59.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 390000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026964579 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.498      |\n",
      "|    explained_variance   | 0.000681    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.5        |\n",
      "|    n_updates            | 1960        |\n",
      "|    policy_gradient_loss | 0.0116      |\n",
      "|    value_loss           | 92.3        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 54.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 387      |\n",
      "|    iterations      | 191      |\n",
      "|    time_elapsed    | 1009     |\n",
      "|    total_timesteps | 391168   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | 59.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 387        |\n",
      "|    iterations           | 192        |\n",
      "|    time_elapsed         | 1014       |\n",
      "|    total_timesteps      | 393216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02077637 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.462     |\n",
      "|    explained_variance   | -7.51e-06  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 54.7       |\n",
      "|    n_updates            | 1970       |\n",
      "|    policy_gradient_loss | 0.0111     |\n",
      "|    value_loss           | 100        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | 58.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 387        |\n",
      "|    iterations           | 193        |\n",
      "|    time_elapsed         | 1019       |\n",
      "|    total_timesteps      | 395264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03709016 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.458     |\n",
      "|    explained_variance   | -3.1e-06   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 66.1       |\n",
      "|    n_updates            | 1980       |\n",
      "|    policy_gradient_loss | 0.0139     |\n",
      "|    value_loss           | 110        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 57.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 387         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 1025        |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016809776 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.504      |\n",
      "|    explained_variance   | 1.16e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51          |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | 0.0191      |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 56.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 387         |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 1030        |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011481056 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.484      |\n",
      "|    explained_variance   | 1.55e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.2        |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | 0.00889     |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=-12.40 +/- 58.30\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | -12.4       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 400000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037044004 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.485      |\n",
      "|    explained_variance   | 1.22e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 69.3        |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | 0.0175      |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 57       |\n",
      "| time/              |          |\n",
      "|    fps             | 387      |\n",
      "|    iterations      | 196      |\n",
      "|    time_elapsed    | 1036     |\n",
      "|    total_timesteps | 401408   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x18a90d97220>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stop_callback = StopTrainingOnRewardThreshold(60, 1)\n",
    "eval_callback = EvalCallback(env, eval_freq=10000, verbose=1, best_model_save_path=save_path)\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=400000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'Saved Models', 'PPO_model2')\n",
    "model.save(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "load_path = os.path.join('Training', 'Saved Models', 'PPO_model2')\n",
    "model = PPO.load(load_path, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59.64, 0.7683749084919419)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:56\n",
      "Episode:2 Score:60\n",
      "Episode:3 Score:60\n",
      "Episode:4 Score:60\n",
      "Episode:5 Score:58\n",
      "Episode:6 Score:60\n",
      "Episode:7 Score:60\n",
      "Episode:8 Score:60\n",
      "Episode:9 Score:58\n",
      "Episode:10 Score:58\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca9f952ef321d99a2ab24cb17ecd9558e5828ac6a303314df963ea7fdd58e81b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('deep-RL-pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
